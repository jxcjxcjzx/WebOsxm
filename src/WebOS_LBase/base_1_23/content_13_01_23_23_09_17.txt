
programming in the
twenty-first century 
It's not about technology for its own sake. It's about being able to implement your ideas.
 


Newest Entry
 Complete Archives
 Subscribe (atom feed)
 
I'm a recovering programmer who has been designing video games since the 1980s, doing things that seem baroquely hardcore in retrospect, like writing Super Nintendo games entirely in assembly language. These days I use whatever tools are the most fun and give me the biggest advantage.
 
james.hague @ gmail.com
 
Where are the comments?
 

A Forgotten Principle of Compiler Design
That a clean system for separately compiled modules appeared in Modula-2, a programming language designed by Niklaus Wirth in 1978, but not in the 2011 C++ standard...hmmm, no further comment needed. But the successor to Modula-2, Oberon, is even more interesting.
 
With Oberon, Wirth removed features from Modula-2 while making a few careful additions. It was a smaller language overall. Excepting the extreme minimalism of Forth, this is the first language I'm aware of where simplicity of the implementation was a concern. For example, nested modules were rarely used in Modula-2, but they were disproportionately complex to compile, so they were taken out of Oberon.
 
That simplicity carried over to optimizations performed by the compiler. Here's Michael Franz:
 Optimizing compilers tend to be much larger and much slower than their straightforward counterparts. Their designers usually do not follow Oberon's maxim of making things "as simple as possible", but are inclined to completely disregard cost (in terms of compiler size, compilation speed, and maintainability) in favor of code-quality benefits that often turn out to be relatively marginal. Trying to make an optimizing compiler as simple as possible and yet as powerful as necessary requires, before all else, a measurement standard, by which both simplicity and power can be judged.
 
For a compiler that is written in the language it compiles, two such standards are easily found by considering first the time required for self-compilation, and then the size of the resulting object program. With the help of these benchmarks, one may pit simplicity against power, requiring that every new capability added to the compiler "pays its own way" by creating more benefit than cost on account of at least one of the measures.
 The principle is "compiler optimizations should pay for themselves." 

Clearly it's not perfect (the Oberon compiler doesn't make heavy use of floating point math, for example, so floating point optimizations may not speed it up or make it smaller), but I like the spirit of it.
 
(If you liked this, you might enjoy Papers from the Lost Culture of Array Languages.)
 permalink April 25, 2012


Previously
Can You Be Your Own Producer?
Use and Abuse of Garbage Collected Languages
100,000 Lines of Assembly Language
This is Why You Spent All that Time Learning to Program
Turning Your Code Inside Out


Deep learning(2012-09-29 06:39:20)转载▼标签： 杂谈 分类： 模式识别  
Deep learning is a sub-field within machine learning that is based on algorithms for learning multiple levels of representation in order to model complex relationships among data. Higher-level features and concepts are thus defined in terms of lower-level ones, and such a hierarchy of features is called a deep architecture; see Bengio (2009) for a review of the field. Most of these models are based on unsupervised learning of representations, and this makes them particularly useful to extract generic abstractions and features from a large corpus of examples, even when these examples are not necessarily labeled, as in semi-supervised learning, and not necessarily of the immediate tasks of interest, as in multi-task learning.
Attempts at training deep architectures (mostly neural networks) before 2006 failed, except for the special case of convolutional neural networks. One of the earliest successful implementations of a deep model (Hinton et al. 2006) involves learning the distribution of high level image (or possibly other data) features using successive layers of binary latent variables. However, real valued variables may also be used.

The approach of (Hinton et al. 2006) uses a restricted Boltzmann machine (Smolensky, 1986) to model each new layer of higher level features. Each new layer guarantees an increase on the lower-bound of the log likelihood of the data, thus improving the model, if trained properly. Once sufficiently many layers have been learned the deep architecture may be used as a generative model by reproducing the data when sampling down the model (an "ancestral pass") from the top level feature activations.

Hinton reports that his models are effective feature extractors over high-dimensional, structured data (Hinton – Scholarpedia, 2009).[1]

[edit] References
Hinton, G. E.; Osindero, S.; Teh, Y. (2006). "A fast learning algorithm for deep belief nets". Neural Computation 18 (7): 1527–1554. doi:10.1162/neco.2006.18.7.1527. PMID 16764513. http://www.cs.toronto.edu/~hinton/absps/fastnc.pdf. 
Smolensky, P. (1986). Information processing in dynamical systems: Foundations of harmony theory.. 1. pp. 194–281. http://portal.acm.org/citation.cfm?id=104290. 
Bengio, Y. (2009). Learning Deep Architectures for AI.. Now Publishers. http://www.iro.umontreal.ca/~bengioy/papers/ftml_book.pdf. 
^ Scholarpedia: Deep Belief Networks - http://www.scholarpedia.org/article/Deep_belief_networks, 2009 


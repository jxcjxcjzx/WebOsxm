
首页资讯精华论坛问答博客专栏群组更多 ▼

 
您还未登录 !登录注册




中国凉茶


博客
微博
相册
收藏
留言
关于我




.




分布式计算Hadoop近期学习总结
博客分类： Hadoop
 
hadoop云计算 .

 
Hadoop学习总结 
Hadoop是什么东西？什么用？ 
（一） Hadoop是什么？ 
  一个开发和运行处理大规模数据的软件平台，是Appach的一个用java语言实现开源软件框架，实现在大量计算机组成的集群中对海量数据进行分布式计算。Hadoop框架中最核心设计就是：HDFS和MapReduce，HDFS实现存储，而MapReduce实现原理分析处理，这两部分是hadoop的核心。数据在Hadoop中处理的流程可以简单的按照下图来理解：数据通过Haddop的集群处理后得到结果，它是一个高性能处理海量数据集的工具。
 
（二） Hadoop为什么如此受欢迎，有什么用？ 

Hadoop开源系统实现了MapReduce编程模型，采用了分布式存储方式提高了读写速度，并扩大了存储容量。采用MapReduce来整合分布式文件系统上的数据，可保证分析和处理数据的高效。与此同时，Hadoop还采用存储冗余数据的方式保证了数据的安全性，Hadoop中的HDFS的高容错性，以及它是基于Java语言开发的，这使得Hadoop可以部署在低廉的计算机集群中，同时不限于某个操作系统。Hadoop中的HDFS的数据管理能力，MapReduce处理任务时的高效率，以及它的开源特性，使其在同类的分布式系统中大放异彩。MapReduce编程模型之所以受到欢迎和迅速得到应用，在技术方面有三方面的原因：
 1.MapReduc所采用的是无共享大规模集群系统，集群系统具有良好的性价比和可伸缩性。 
2.MapReduce编程模型简单，易于理解，易于使用。 
3.虽然基本的MapReduce模型只提供一个过程性的编程接口，但是在海量的数据环境，需要保证可伸缩性的前提下，通过使用适合的查询优化和索引技术，MapReduce仍然能够提供相当好的数据处理性能。
 Hadoop的优缺点介绍： 
（一） 优点： 
（一）高可靠性。Hadoop按位存储和处理数据的能力值得人们信赖; 
（二）高扩展性。Hadoop是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。 
（三）高效性。Hadoop能够在节点之间动态地移动数据，并保证各个节点的动态平衡，因此处理速度非常快。 
（四）高容错性。Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。 
（二） 缺点： 
（一）不适合低延迟数据访问。 
（二）无法高效存储大量小文件。 
（三）不支持多用户写入及任意修改文件。 
Hadoop集群的组成介绍： 
(一) Hadoop家族由以下几个子项目组成 
整个Hadoop家族由以下几个子项目组成，现在Hadoop已经发展成为包含多个子项目的集合。虽然其核心内容是MapReduce和Hadoop分布式文件系统（HDFS），但是在Hadoop下的Common、Avro、Chukwa、Hive、HBase等子项目也是不可或缺的。他们在提供了互补性服务或在核心层上提供了更高层的服务。
 
1). Core/Common 
从Hadoop0.20版本开始，Hadoop Core项目便更名为Common。它是Hadoop体系最底层的一个模块，为Hadoop各子项目提供各种工具，如：FileSystem、RPC和串行化库，他们为在廉价的硬件上搭建云计算环境提供基本的服务，并且为运行在该平台上的软件开发提供了所需的API，配置文件和日志操作等。
 2) . Avro 
Avro是用于数据序列化的系统。它提供了丰富的数据结构类型、快速可压缩 
的二进制数据格式、存储持久性数据的文件集、远程调用RPC的功能和简单的动态语言集成功能。其中，代码生成器既不需要读写文件数据，也不需要使用或实现RPC协议，它只是一个可选的对静态类型语言的实现。
 Avro系统依赖于模式（Schema），Avro数据的读和写是在模式之下完成的。这样就可以 
减少写入数据的开销，提高序列化的速度并缩减其大小。同时，也可以方便动态脚本语言的使用，因为数据连同其模式都是自描述的。 
在RPC中，Avro系统的客户端和服务端通过握手协议进行模式的交换。因此当客户端 
和服务端拥有彼此全部的模式时，不同模式下的相同命名字段、丢失字段和附加字段等信息的一致性问题就得到了很好的解决。 
3). Chukwa 
Chukwa：Chukwa是开源的数据收集系统，用于监控和分析大型分布式系统的数据。 
Chukwa是在Hadoop的HDFS和MapReduce框架之上搭建的，它同时继承了Hadoop的可扩展性和健壮性。Chukwa通过HDFS来存储数据，并依赖于MapReduce任务处理数据。
 Chukwa中也附带了灵活且强大的工具，用于显示、监视和分析数据结果，以便更好地利用所收集的数据。 
4). HBase 
基于Hadoop Distributed File System，是一个开源的，基于列存储模型的分布式数据库。 
5). HDFS 
是一个分布式文件系统。由于HDFS具有高容错性（fault-tolerant）的特点，所以可以设计部署在低廉（low-cost）的硬件上。它可以通过提供高吞吐率（highthroughput）来访问应用程序的数据，适合那些有着超大数据集的应用程序。HDFS放宽了可移植操作系统接口（POSIX，Portable Operating System Interface）的要求，这样就可以实现以流的形式访问文件系统中的数据。HDFS原本是开源的Apache项目Nutch的基础结构，最后它成为了Hadoop的基础架构之一。
 以下是HDFS的设计目标： 
  检测和快速恢复硬件故障。硬件故障是常见的问题，整个HDFS系统由数百台或数千 
台存储着数据文件的服务器组成，而如此多的服务器意味着高故障率，因此，故障的 
检测和自动快速恢复是HDFS的一个核心目标。 
  流式的数据访问。HDFS使应用程序能流式地访问它们的数据集。HDFS被设计成适 
合进行批量处理，而不是用户交互式的处理。所以它重视数据吞吐量，而不是数据访 
问的反应速度。 
  简化一致性模型。大部分的HDFS程序操作文件时需要一次写入，多次读取。一个文 
件一旦经过创建、写入、关闭之后就不需要修改了，从而简化了数据一致性问题和高 
吞吐量的数据访问问题。 
  通信协议。所有的通信协议都在TCP/IP协议之上。一个客户端和明确配置了端口的 
名字节点（NameNode）建立连接之后，它和名称节点（NameNode）的协议便是客户 
端协议（Client Protocal）。数据节点（DataNode）和名字节点（NameNode）之间则 
用数据节点协议（DataNode Protocal）。 
6). Hive 
Hive最早是由Facebook设计的，是一个建立在Hadoop基础之上的数据仓库， 
它提供了一些用于数据整理、特殊查询和分析存储在Hadoop文件中的数据集的工具。Hive 
提供的是一种结构化数据的机制，它支持类似于传统RDBMS中的SQL语言来帮助那些熟悉SQL的用户查询Hadoop中的数据，该查询语言称为Hive QL。与此同时，那些传统的MapReduce编程人员也可以在Mapper或Reducer中通过Hive QL查询数据。Hive编译器会把Hive QL编译成一组MapReduce任务，从而方便MapReduce编程人员进行Hadoop应用的开发。
 7). MapReduce 
实现了MapReduce编程框架 
8). Pig 
Pig是一个对大型数据集进行分析和评估的平台。Pig最突出的优势是它的 
结构能够经受住高度并行化的检验，这个特性让它能够处理大型的数据集。目前，Pig 
的底层由一个编译器组成，它在运行的时候会产生一些MapReduce程序序列，Pig的语 
言层由一种叫做Pig Latin的正文型语言组成。 
9). ZooKeeper 
Zookeeper 是Google的Chubby一个开源的实现。它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。 ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。
 (二) HDFS的体系结构 
我们首先介绍HDFS的体系结构，HDFS采用了主从（Master/Slave）结构模型，一个HDFS集群是由一个NameNode和若干个DataNode组成的。其中NameNode作为主服务器，管理文件系统的命名空间和客户端对文件的访问操作；集群中的DataNode管理存储的数据。HDFS允许用户以文件的形式存储数据。从内部来看，文件被分成若干个数据块，而且这若干个数据块存放在一组DataNode上。NameNode执行文件系统的命名空间操作，比如打开、关闭、重命名文件或目录等，它也负责数据块到具体DataNode的映射。DataNode负责处理文件系统客户端的文件读写请求，并在NameNode的统一调度下进行数据块的创建、删除和复制工作。
 NameNode和DataNode都被设计成可以在普通商用计算机上运行。这些计算机通常运行的是GNU/Linux操作系统。HDFS采用Java语言开发，因此任何支持Java的机器都可以部署NameNode和DataNode。一个典型的部署场景是集群中的一台机器运行一个NameNode实例，其他机器分别运行一个DataNode实例。当然，并不排除一台机器运行多个DataNode实例的情况。集群中单一的NameNode的设计则大大简化了系统的架构。NameNode是所有HDFS元数据的管理者，用户数据永远不会经过NameNode。
 Hadoop组成主要由 NameNode,DataNode,Secondary NameNode,JobTracker,TaskTracker组成。 

（一）NameNode中记录了文件是如何被拆分成block以及这些block都存储到了那些DateNode节点，同时保存了文件系统运行的状态信息。 （Block（块）：一个文件分块，默认64M）
 （二）DataNode中存储的是被拆分的blocks。 
（三）Secondary NameNode帮助NameNode收集文件系统运行的状态信息。 
（四）JobTracker当有任务提交到Hadoop集群的时候负责Job的运行,负责调度多个TaskTracker。 
（五）TaskTracker负责某一个map或者reduce任务。 
(三) MapReduce的体系结构 
     接下来介绍MapReduce的体系结构，MapReduce是一种并行编程模式，这种模式使得 
软件开发者可以轻松地编写出分布式并行程序。在Hadoop的体系结构中，MapReduce是一 
个简单易用的软件框架，基于它可以将任务分发到由上千台商用机器组成的集群上，并以一 
种高容错的方式并行处理大量的数据集，实现Hadoop的并行任务处理功能。MapReduce框 
架是由一个单独运行在主节点上的JobTracker和运行在每个集群从节点上的TaskTracker共 
同组成的。主节点负责调度构成一个作业的所有任务，这些任务分布在不同的从节点上。主 
节点监控它们的执行情况，并且重新执行之前失败的任务；从节点仅负责由主节点指派的任 
务。当一个Job被提交时，JobTracker接收到提交作业和配置信息之后，就会将配置信息等 
分发给从节点，同时调度任务并监控TaskTracker的执行。 
从上面的介绍可以看出，HDFS和MapReduce共同组成了Hadoop分布式系统体系结构 
的核心。HDFS在集群上实现了分布式文件系统，MapReduce在集群上实现了分布式计算和 
任务处理。HDFS在MapReduce任务处理过程中提供了文件操作和存储等支持，MapReduce 
在HDFS的基础上实现了任务的分发、跟踪、执行等工作，并收集结果，二者相互作用，完 
成了Hadoop分布式集群的主要任务。 
(四) MapReduce并行运行原理 
MapReduce计算模型非常适合在大量计算机组成的大规模集群上并行运行。每一个 map 任务和每一个reduce 任务均可以同时运行于一个单独的计算节点上，可想而知，其运算效率是很高的，那么这样的并行计算是如何做到的呢？下面将简单介绍一下其原理。
 
1. 数据分布存储 
Hadoop分布式文件系统（HDFS）由一个名称节点（NameNode ）和N个数据节点 （DataNode）组成，每个节点均是一台普通的计算机。在使用方式上HDFS与我们熟悉的单机文件系统非常类似，它可以创建目录，创建、复制和删除文件，以及查看文件的内容等。但HDFS底层把文件切割成了Block，然后这些 Block 分散地存储于不同的 DataNode 上，每个 Block 还可以复制数份数据存储于不同的 DataNode 上，达到容错容灾的目的。NameNode 则是整个 HDFS 的核心，它通过维护一些数据结构来记录每一个文件被切割成了多少个Block、这些 Block 可以从哪些 DataNode 中获得，以及各个 DataNode 的状态等重要信息。
 
2. 分布式并行计算 
Hadoop 中有一个作为主控的 JobTracker，用于调度和管理其他的 TaskTracker，JobTracker 可以运行于集群中的任意一台计算机上。TaskTracker则负责执行任务，它必须运行于 DataNode 上，也就是说DataNode 既是数据存储节点，也是计算节点。 JobTracker 将 map 任务和 reduce 任务分发给空闲的 TaskTracker，让这些任务并行运行，并负责监控任务的运行情况。如果某一个 TaskTracker 出了故障，JobTracker 会将其负责的任务转交给另一个空闲的 TaskTracker 重新运行。
 
3. 本地计算 
数据存储在哪一台计算机上，就由哪台计算机进行这部分数据的计算，这样可以减少数 
据在网络上的传输，降低对网络带宽的需求。在 Hadoop 这类基于集群的分布式并行系统中，计算节点可以很方便地扩充，它所能够提供的计算能力近乎无限，但是由于数据需要在不同的计算机之间流动，故网络带宽变成了瓶颈，“本地计算”是一种最有效的节约网络带宽的手段，业界把这形容为“移动计算比移动数据更经济”。
 
4. 任务粒度 
把原始大数据集切割成小数据集时，通常让小数据集小于或等于 HDFS 中一个 Block 的 
大小（默认是64MB），这样能够保证一个小数据集是位于一台计算机上的，便于本地计算。有 M 个小数据集待处理，就启动 M 个 map 任务，注意这 M 个map 任务分布于 N 台计算机上，它们会并行运行，reduce 任务的数量 R 则可由用户指定。
 
5. 数据分割（Partition） 
把 map 任务输出的中间结果按 key 的范围划分成R份（R是预先定义的reduce 任务的 
个数），划分时通常使用 hash 函数（如：hash(key) mod R），这样可以保证某一范围内的 key一定是由一个 reduce 任务来处理的，可以简化 Reduce 的过程。
 
6. 数据合并（Combine） 
在数据分割之前，还可以先对中间结果进行数据合并（Combine），即将中间结果中有相 
同 key的 <key, value> 对合并成一对。Combine 的过程与reduce 的过程类似，很多情况下可以直接使用reduce 函数，但 Combine 是作为map 任务的一部分，在执行完map函数后紧接着执行的。Combine 能够减少中间结果中 <key, value> 对的数目，从而降低网络流量。
 
7. Reduce 
Map 任务的中间结果在做完 Combine 和 Partition 之后，以文件形式存于本地磁盘 
上。中间结果文件的位置会通知主控 JobTracker，JobTracker 再通知 reduce 任务到哪一个 DataNode 上去取中间结果。注意，所有的map 任务产生的中间结果均按其key 值用同一个 hash 函数划分成了R份，R个reduce 任务各自负责一段key 区间。每个reduce 需要向许多个map 任务节点取得落在其负责的key 区间内的中间结果，然后执行reduce函数，形成一个最终的结果文件。
 
8. 任务管道 
有 R 个 reduce 任务，就会有 R 个最终结果，很多情况下这 R 个最终结果并不需要合并成一个最终结果，因为这 R 个最终结果又可以作为另一个计算任务的输入，开始另一个并行计算任务，这也就形成了任务管道。
 (五) HDFS的数据管理 
HDFS是分布式计算的存储基石，Hadoop分布式文件系统和其他分布式文件系统有很多类似的特质： 
  对于整个集群有单一的命名空间； 
  具有数据一致性。适合一次写入多次读取的模型，客户端在文件没有被成功创建之前是无法看到文件存在的； 
  文件会被分割成多个文件块，每个文件块被分配存储到数据节点上，而且会根据配置由复制文件块来保证数据的安全性。 

HDFS通过三个重要的角色来进行文件系统的管理： 
NameNode、DataNode和Client。NameNode可以看做是分布式文件系统中的管理者，主要负责管理文件系统的命名空间、集群配置信息和存储块的复制等。NameNode会将文件系统的 Metadata存储在内存中，这些信息主要包括文件信息、每一个文件对应的文件块的信息和每一个文件块在DataNode中的信息等。 DataNode是文件存储的基本单元，它将文件块（Block）存储在本地文件系统中，保存了所有Block的Metadata，同时周期性地将所有存在的 Block信息发送给NameNode。Client就是需要获取分布式文件系统文件的应用程序。以下通过三个具体的操作来说明HDFS对数据的管理。
 （1）文件写入 
1） Client向NameNode发起文件写入的请求。 
2）NameNode根据文件大小和文件块的配置情况，返回给Client它所管理的DataNode 
的信息。 
3）Client将文件划分为多个Block，根据DataNode的地址信息，按顺序将其写入每一 
个DataNode块中。 
（2）文件读取 
1） Client向NameNode发起读取文件的请求。 
2） NameNode返回文件存储的DataNode信息。 
3）Client读取文件信息。 
（3）文件块（Block）复制 
1） NameNode发现部分文件的Block不符合最小复制数这一要求或部分DataNode失效。 
2）通知DataNode相互复制Block。 
3）DataNode开始直接相互复制。 

HDFS作为分布式文件系统在数据管理方面还有几个值得借鉴的功能： 
  文件块（Block）的放置：一个Block会有三份备份，一份放在NameNode指定的 
DataNode上，另一份放在与指定的DataNode不在同一台机器上的DataNode上，最 
后一份放在与指定的DataNode在同一Rack上的DataNode上。备份的目的是为了数 
据安全，采用这种配置方式主要是考虑同一Rack失败的情况，以及不同Rack之间的 
数据拷贝会带来的性能问题。 
  心跳检测：用心跳检测DataNode的健康状况，如果发现问题就采取数据备份的方式 
来保证数据的安全性。 
  数据复制（场景为DataNode失败、需要平衡DataNode的存储利用率和平衡 
DataNode数据交互压力等情况）：使用Hadoop时可以用HDFS的balancer命令配置 
Threshold来平衡每一个DataNode的磁盘利用率。假设设置了Threshold为10%，那 
么执行balancer命令的时候，首先会统计所有DataNode的磁盘利用率的平均值，然 
后判断如果某一个DataNode的磁盘利用率超过这个均值，那么将会把这个DataNode 
的block转移到磁盘利用率低的DataNode上，这对于新节点的加入来说十分有用。 
  数据校验：采用CRC32做数据校验。在写入文件Block的时候，除了写入数据外还 
会写入校验信息，在读取的时候则需要校验后再读入。 
  单个NameNode：如果失败，任务处理信息将会记录在本地文件系统和远端的文件系 
统中。 
  数据管道性的写入：当客户端要写入文件到DataNode上时，客户端首先会读取一个 
Block，然后写到第一个DataNode上，接着由第一个 DataNode将其传递到备份的 
DataNode上，直到所有需要写入这个Block的DataNode都成功写入后，客户端才会 
开始写下一个 Block。 
  安全模式：分布式文件系统启动的时候会有安全模式（系统运行期间也可以通过命令 
进入安全模式），当分布式文件系统处于安全模式时，文件系统中的内容不允许修改 
也不允许删除，直到安全模式结束。安全模式主要是为了在系统启动的时候检查各 
个DataNode上的数据块的有效性，同时根据策略进行必要的复制或删除部分数据块。 
在实际操作过程中，若在系统启动时修改和删除文件会出现安全模式不允许修改的错 
误提示，需要等待片刻即可恢复。 




1 
顶

0 
踩.

分享到： 
.

JFreeChart生成折线图（生成图片本地保存， ...

6 小时前
浏览 224
评论(2)
分类:互联网
相关推荐


评论


2 楼 中国凉茶6 小时前   

大家来讲讲Hadoop的前景和自己的认识吧！
 

1 楼 中国凉茶6 小时前   

这是再公司的要求下学习了两个星期的结果，但是边学变忘，等到总结到最后的时候，发现以前学习的都忘了，唉 


发表评论

 您还没有登录,请您登录后再发表评论 






中国凉茶
 
浏览: 21135 次
性别: 
来自: 北京



最近访客 更多访客>>




X_Goder




anjero




yulongblue




hareamao
.

文章分类
■全部博客 (71)
■Java code (32)
■Java web util (5)
■JS Code (11)
■Jquery (7)
■DB (1)
■paper (29)
■非技术 (3)
■struts (2)
■Java HttpClient深入分析 (1)
■javamail (1)
■JfreeChart (3)
■Hadoop (3)


社区版块
■我的资讯 (0)
■我的论坛 (0) 
■我的问答 (0)


存档分类
■2013-01 (1)
■2012-12 (4)
■2012-11 (20)
■更多存档...


评论排行榜
■Tomcat负载均衡和集群环境的搭建
■Java URL与URLConnection
■JQuery,Extjs,YUI,Prototype,Dojo 等JS框架 ...
■Tomcat6.0 配置ip地址访问不用加端口和项目 ...
■类似淘宝放大镜代码


最新评论
longying2008： 个人感觉可以在data = (Element) itr.nex ...
Java读取XML配置文件详细总结（dom4j方式）
中国凉茶： lord_is_layuping 写道有曲线图没？我博客没有搞 ...
JfreeChart折线图
lord_is_layuping： 有曲线图没？
JfreeChart折线图
cwqcwqmax9： 值得一看啊
Tomcat负载均衡和集群环境的搭建
zhangyaochun： 一看就不是互联网人写的，kissy|tangram|qwrap ...
JQuery,Extjs,YUI,Prototype,Dojo 等JS框架的区别和应用场景简述

.


--------------------------------------------------------------------------------
声明：ITeye文章版权属于作者，受法律保护。没有作者书面许可不得转载。若作者同意转载，必须以超链接形式标明文章原始出处和作者。
© 2003-2012 ITeye.com. All rights reserved. [ 京ICP证110151号 京公网安备110105010620 ] 
.
